<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [whatwg] A standard for adaptive HTTP streaming for media resources
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20A%20standard%20for%20adaptive%20HTTP%20streaming%20for%20media%0A%20resources&In-Reply-To=%3CPine.LNX.4.64.1008192358570.1138%40ps20323.dreamhostps.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="070356.html">
   <LINK REL="Next"  HREF="070297.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[whatwg] A standard for adaptive HTTP streaming for media resources</H1>
<!--htdig_noindex-->
    <B>Ian Hickson</B> 
    <A HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20A%20standard%20for%20adaptive%20HTTP%20streaming%20for%20media%0A%20resources&In-Reply-To=%3CPine.LNX.4.64.1008192358570.1138%40ps20323.dreamhostps.com%3E"
       TITLE="[whatwg] A standard for adaptive HTTP streaming for media resources">ian at hixie.ch
       </A><BR>
    <I>Thu Aug 19 18:08:25 PDT 2010</I>
    <P><UL>
        <LI>Previous message: <A HREF="070356.html">[whatwg] On implementing videos with multiple tracks in HTML5
</A></li>
        <LI>Next message: <A HREF="070297.html">[whatwg] A standard for adaptive HTTP streaming for media	resources
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#70296">[ date ]</a>
              <a href="thread.html#70296">[ thread ]</a>
              <a href="subject.html#70296">[ subject ]</a>
              <a href="author.html#70296">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--/htdig_noindex-->
<!--beginarticle-->
<PRE>On Tue, 25 May 2010, Silvia Pfeiffer wrote:
&gt;<i> 
</I>&gt;<i> We've in the past talked about how there is a need to adapt the bitrate 
</I>&gt;<i> version of a audio or video resource that is being delivered to a user 
</I>&gt;<i> agent based on the available bandwidth on the network, the available CPU 
</I>&gt;<i> cycles, and possibly other conditions.
</I>&gt;<i> 
</I>&gt;<i> It has been discussed to do this using @media queries and providing 
</I>&gt;<i> links to alternative versions of a media resources through the &lt;source&gt; 
</I>&gt;<i> element inside it. But this is a very inflexible solution, since the 
</I>&gt;<i> side conditions for choosing a bitrate version may change over time and 
</I>&gt;<i> what is good at the beginning of video playback may not be good 2 
</I>&gt;<i> minutes later (in particular if you're on a mobile device driving 
</I>&gt;<i> through town).
</I>&gt;<i> 
</I>&gt;<i> Further, we have discussed the need for supporting a live streaming 
</I>&gt;<i> approach such as RTP/RTSP - but RTP/RTSP has its own &quot;non-Web&quot; issues 
</I>&gt;<i> that will make it difficult to make it part of a Web application 
</I>&gt;<i> framework - in particular it request a custom server and won't just work 
</I>&gt;<i> with a HTTP server.
</I>&gt;<i> 
</I>&gt;<i> In recent times, vendors have indeed started moving away from custom 
</I>&gt;<i> protocols and custom servers and have moved towards more intelligence in 
</I>&gt;<i> the UA and special approaches to streaming over HTTP.
</I>&gt;<i> 
</I>&gt;<i> Microsoft developed &quot;Smooth Streaming&quot;, Apple developed &quot;HTTP Live 
</I>&gt;<i> Streaming&quot; and Adobe recently launched &quot;HTTP Dynamic Streaming&quot;. (Also 
</I>&gt;<i> see a comparison at). As these vendors are working on it for MPEG files, 
</I>&gt;<i> so are some people for Ogg. I'm not aware anyone is looking at it for 
</I>&gt;<i> WebM yet.
</I>&gt;<i> 
</I>&gt;<i> Standards bodies haven't held back either. The 3GPP organisation have 
</I>&gt;<i> defined 3GPP adaptive HTTP Streaming (AHS) in their March 2010 release 9 
</I>&gt;<i> of 3GPP. Now, MPEG has started consolidating approaches for adaptive 
</I>&gt;<i> bitrate streaming over HTTP for MPEG file formats.
</I>&gt;<i> 
</I>&gt;<i> Adaptive bitrate streaming over HTTP is the correct approach towards 
</I>&gt;<i> solving the double issues of adapting to dynamic bandwidth availability, 
</I>&gt;<i> and of providing a live streaming approach that is reliable.
</I>&gt;<i> 
</I>&gt;<i> Right now, no standard exists that has been proven to work in a 
</I>&gt;<i> format-independent way. This is particularly an issue for HTML5, where 
</I>&gt;<i> we want at least support for MPEG4, Ogg Theora/Vorbis, and WebM.
</I>&gt;<i> 
</I>&gt;<i> I know that it is not difficult to solve this issue in a 
</I>&gt;<i> format-independent way, which is why solutions are jumping up 
</I>&gt;<i> everywhere. They are, however, not compatible and create a messy 
</I>&gt;<i> environment where people have to install solutions for multiple 
</I>&gt;<i> different approaches to make sure they are covered for different 
</I>&gt;<i> platforms, different devices, and different formats. It's a clear 
</I>&gt;<i> situation where a new standard is necessary.
</I>&gt;<i> 
</I>&gt;<i> The standard basically needs to provide three different things:
</I>&gt;<i> * authoring of content in a specific way
</I>&gt;<i> * description of the alternative files on the server and their
</I>&gt;<i> features for the UA to download and use for switching
</I>&gt;<i> * a means to easily switch mid-way between these alternative files
</I>
On Mon, 24 May 2010, Chris Holland wrote:
&gt;<i> 
</I>&gt;<i> I don't have something decent to offer for the first and last bullets 
</I>&gt;<i> but I'd like to throw-in something for the middle bullet:
</I>&gt;<i> 
</I>&gt;<i> The http protocol is vastly under-utilized today when it comes to URIs 
</I>&gt;<i> and the various Accept* headers.
</I>&gt;<i> 
</I>&gt;<i> Today developers might embed an image in a document as chris.png. Web 
</I>&gt;<i> daemons know to find that resource and serve it, in this sense, 
</I>&gt;<i> chris.png is a resource locator.
</I>&gt;<i> 
</I>&gt;<i> Technically one might reference the image as a resource identifier named 
</I>&gt;<i> &quot;chris&quot;. The user's browser may send &quot;image/gif&quot; as the only value of an 
</I>&gt;<i> accept header, signaling the following to the server: &quot;I'm supposed to 
</I>&gt;<i> download an image of chris here, but I only support gif, so don't bother 
</I>&gt;<i> sending me a .png&quot;. In a perhaps more useful scenario the user agent may 
</I>&gt;<i> tell the server &quot;don't bother sending me an image, I'm a screen reader, 
</I>&gt;<i> do you have anything my user could listen to?&quot;. In this sense, the 
</I>&gt;<i> document's author didn't have to code against or account for every 
</I>&gt;<i> possible &quot;context&quot; out there, the author merely puts a reference to a 
</I>&gt;<i> higher-level representation that should remain forward-compatible with 
</I>&gt;<i> evolving servers and user-agents.
</I>&gt;<i> 
</I>&gt;<i> By passing a list of accepted mimetypes, the accept http header provides 
</I>&gt;<i> this ability to serve context-aware resources, which starts to feel like 
</I>&gt;<i> a contender for catering to your middle bullet.
</I>&gt;<i> 
</I>&gt;<i> To that end, new mime-types could be defined to encapsulate media 
</I>&gt;<i> type/bit rate combinations.
</I>&gt;<i> 
</I>&gt;<i> Or the accept header might remain confined to media types and acceptable 
</I>&gt;<i> bit rate information might get encapsulated into a new header, such as: 
</I>&gt;<i> X-Accept-Bitrate .
</I>&gt;<i> 
</I>&gt;<i> If you combined the above approach with existing standards for http byte 
</I>&gt;<i> range requests, there may be a mechanism there to cater to your 3rd 
</I>&gt;<i> bullet as well: when network conditions deteriorate, the client could 
</I>&gt;<i> interrupt the current stream and issue a new request &quot;where it left off&quot; 
</I>&gt;<i> to the server. Although this likel wouldn't work because a byte range 
</I>&gt;<i> request would mean nothing on files of two different sizes. For 
</I>&gt;<i> playbacked media, time codes would be needed to define range.
</I>
On Tue, 25 May 2010, Silvia Pfeiffer wrote:
&gt;<i> 
</I>&gt;<i> That's not quite sufficient, actually. You need to know which byte range 
</I>&gt;<i> to retrieve or which file segment. Apple solved it by introducing a m3u8 
</I>&gt;<i> file format, Microsoft by introducing a SMIL-based server manifest file, 
</I>&gt;<i> Adobe by introducing a XML-based Flash Media Manifest file F4M. That 
</I>&gt;<i> kind of complexity canot easily be transferred through HTTP headers.
</I>&gt;<i>
</I>&gt;<i> The idea of the manifest file is to provide matching transition points 
</I>&gt;<i> between the different files of different bitrate to segments or byte 
</I>&gt;<i> ranges. This information has to somehow come to the UA (amongst other 
</I>&gt;<i> information as available in typical manifest files). I don't think that 
</I>&gt;<i> can be achieved without a manifest file.
</I>
On Fri, 28 May 2010, Jeroen Wijering wrote:
&gt;<i> 
</I>&gt;<i> Indeed, one such key condition is the current dimensions of the video 
</I>&gt;<i> window. Tracking this condition allows user-agents to:
</I>&gt;<i> 
</I>&gt;<i> *) Not waste bandwidth, e.g. by pushing a 720p video in a 320x180 video 
</I>&gt;<i> tag.
</I>&gt;<i>
</I>&gt;<i> *) Respond to changes in the video display, e.g. when the video is 
</I>&gt;<i> switched to fullscreen playback.
</I>&gt;<i> 
</I>&gt;<i> Providing the different media options using &lt;source&gt; elements might 
</I>&gt;<i> still work out fine, if there's a clearly defined API that covers all 
</I>&gt;<i> scenarios. A rough example:
</I>&gt;<i> 
</I>&gt;<i> &lt;video&gt;
</I>&gt;<i>   &lt;source bitrate=&quot;100&quot; height=&quot;120&quot; src=&quot;video_100.mp4&quot; type=&quot;video/mp4; codecs='avc1.42E01E, mp4a.40.2'; keyframe-interval='00:02'&quot; width=&quot;160&quot;&gt;
</I>&gt;<i>   &lt;source bitrate=&quot;500&quot; height=&quot;240&quot; src=&quot;video_500.mp4&quot; type=&quot;video/mp4; codecs='avc1.42E01E, mp4a.40.2'; keyframe-interval ='00:02'&quot; width=&quot;320&quot;&gt;
</I>&gt;<i>   &lt;source bitrate=&quot;900&quot; height=&quot;540&quot; src=&quot;video_900.mp4&quot; type=&quot;video/mp4; codecs='avc1.42E01E, mp4a.40.2'; keyframe-interval ='00:02'&quot; width=&quot;720&quot;&gt; 
</I>&gt;<i> &lt;/video&gt;
</I>&gt;<i> 
</I>&gt;<i> This example would tell the user-agent that the three MP4 files have a 
</I>&gt;<i> keyframe-interval of 2 seconds - which of course raises the issue that 
</I>&gt;<i> fixed keyframe-intervals would be required.
</I>&gt;<i> 
</I>&gt;<i> The user-agent can subsequently use e.g. the Media Fragments API to 
</I>&gt;<i> request chunks, switching between sources as the conditions change.
</I>
It seems to me that we are not lacking in solutions in this space -- it 
would behoove us to try to leverage the existing solutions rather than 
making up new ones. Have the above solutions been tried in browsers?

-- 
Ian Hickson               U+1047E                )\._.,--....,'``.    fL
<A HREF="http://ln.hixie.ch/">http://ln.hixie.ch/</A>       U+263A                /,   _.. \   _\  ;`._ ,.
Things that are impossible just take longer.   `._.-(,_..'--(,_..'`-.;.'

</PRE>

<!--endarticle-->
<!--htdig_noindex-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="070356.html">[whatwg] On implementing videos with multiple tracks in HTML5
</A></li>
	<LI>Next message: <A HREF="070297.html">[whatwg] A standard for adaptive HTTP streaming for media	resources
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#70296">[ date ]</a>
              <a href="thread.html#70296">[ thread ]</a>
              <a href="subject.html#70296">[ subject ]</a>
              <a href="author.html#70296">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">More information about the whatwg
mailing list</a><br>
<!--/htdig_noindex-->
</body></html>
