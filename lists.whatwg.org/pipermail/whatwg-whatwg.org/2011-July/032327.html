<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [whatwg] Peer-to-peer communication, video conferencing, &lt;device&gt;, and related topics
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20Peer-to-peer%20communication%2C%20video%20conferencing%2C%0A%20%3Cdevice%3E%2C%20and%20related%20topics&In-Reply-To=%3C1309931809.4058.148699.camel%40robslapu%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="032326.html">
   <LINK REL="Next"  HREF="032417.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[whatwg] Peer-to-peer communication, video conferencing, &lt;device&gt;, and related topics</H1>
<!--htdig_noindex-->
    <B>Rob Manson</B> 
    <A HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20Peer-to-peer%20communication%2C%20video%20conferencing%2C%0A%20%3Cdevice%3E%2C%20and%20related%20topics&In-Reply-To=%3C1309931809.4058.148699.camel%40robslapu%3E"
       TITLE="[whatwg] Peer-to-peer communication, video conferencing, &lt;device&gt;, and related topics">roBman at mob-labs.com
       </A><BR>
    <I>Tue Jul  5 22:56:49 PDT 2011</I>
    <P><UL>
        <LI>Previous message: <A HREF="032326.html">[whatwg] Peer-to-peer communication, video conferencing, &lt;device&gt;, and related topics
</A></li>
        <LI>Next message: <A HREF="032417.html">[whatwg] PeerConnection, MediaStream, getUserMedia(),	and other feedback
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#32327">[ date ]</a>
              <a href="thread.html#32327">[ thread ]</a>
              <a href="subject.html#32327">[ subject ]</a>
              <a href="author.html#32327">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--/htdig_noindex-->
<!--beginarticle-->
<PRE>There are also tablet devices with stereo cameras on the back and single
on the front too.  Stereo will become increasingly common.


roBman


On Wed, 2011-07-06 at 10:55 +0530, Shwetank Dixit wrote:
&gt;<i> On Fri, 18 Mar 2011 19:32:49 +0530, Lachlan Hunt  
</I>&gt;<i> &lt;<A HREF="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">lachlan.hunt at lachy.id.au</A>&gt; wrote:
</I>&gt;<i> 
</I>&gt;<i> &gt; On 2011-03-18 05:45, Ian Hickson wrote:
</I>&gt;<i> &gt;&gt; On Thu, 16 Sep 2010, Jonathan Dixon wrote:
</I>&gt;<i> &gt;&gt;&gt; Further, it could be useful to provide a way to query the video source
</I>&gt;<i> &gt;&gt;&gt; as to whether the camera is oriented relative to the screen (if the
</I>&gt;<i> &gt;&gt;&gt; underlying system knows; consider a phone device with both a main  
</I>&gt;<i> &gt;&gt;&gt; camera
</I>&gt;<i> &gt;&gt;&gt; and self-view camera). This is needed to drive the decision on whether
</I>&gt;<i> &gt;&gt;&gt; to do this horizontal flip or not. In fact, such an application may  
</I>&gt;<i> &gt;&gt;&gt; want
</I>&gt;<i> &gt;&gt;&gt; to somehow indicate a preference for the self-view camera when multiple
</I>&gt;<i> &gt;&gt;&gt; cameras are present in the selection list. c.f. a movie-making app  
</I>&gt;<i> &gt;&gt;&gt; which
</I>&gt;<i> &gt;&gt;&gt; would prefer the outward facing camera.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; Interesting.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; In getUserMedia() the input is extensible; we could definitely add
</I>&gt;<i> &gt;&gt; &quot;prefer-user-view&quot; or &quot;prefer-environment-view&quot; flags to the method  
</I>&gt;<i> &gt;&gt; (with
</I>&gt;<i> &gt;&gt; better names, hopefully, but consider that 'rear' and 'front' are
</I>&gt;<i> &gt;&gt; misleading terms -- the front camera on a DSLR faces outward from the
</I>&gt;<i> &gt;&gt; user, the front camera on a mobile phone faces toward the user). The  
</I>&gt;<i> &gt;&gt; user
</I>&gt;<i> &gt;&gt; still has to OK the use of the device, though, so maybe it should just  
</I>&gt;<i> &gt;&gt; be
</I>&gt;<i> &gt;&gt; left up to the user to pick the camera? They'll need to be able to  
</I>&gt;<i> &gt;&gt; switch
</I>&gt;<i> &gt;&gt; it on the fly, too, which again argues to make this a UA feature.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; We could just add flags to the options string like this:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; &quot;video;view=user, audio&quot; or &quot;video;view=environment, audio&quot;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; It's worth pointing out that The HTML Media Capture draft from the DAP  
</I>&gt;<i> &gt; WG uses the terms &quot;camera&quot; and &quot;camcorder&quot; for this purpose, but I find  
</I>&gt;<i> &gt; these terms to be very ambiguous and inappropriate, and so we should not  
</I>&gt;<i> &gt; use them here.
</I>&gt;<i> Just wanted to know whether there is any consensus on this or not? Mobile  
</I>&gt;<i> phones are coming out with dual cameras (front and back facing) and  
</I>&gt;<i> depending on the use case, the developer might want access to either the  
</I>&gt;<i> front or back one. (For example, for a simple camera app, a back facing  
</I>&gt;<i> will do, but for a web conferencing app, the front facing will be  
</I>&gt;<i> required). At least, the developer should be able to specify which one to  
</I>&gt;<i> enable by default, which then can be changed the user if needed.
</I>&gt;<i> 
</I>&gt;<i> Another question is flash. As far as I have seen, there seems to be no  
</I>&gt;<i> option to specify whether the camera needs to use flash or not. Is this  
</I>&gt;<i> decision left up to the device? (If someone is making an app which is just  
</I>&gt;<i> clicking a picture of the person, then it would be nice to have the camera  
</I>&gt;<i> use flash in low light conditions).
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; <A HREF="http://dev.w3.org/2009/dap/camera/">http://dev.w3.org/2009/dap/camera/</A>
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;&gt; Similarly for exposing the kind of stream: we could add to  
</I>&gt;<i> &gt;&gt; GeneratedStream
</I>&gt;<i> &gt;&gt; an attribute that reports this kind of thing. What is the most useful  
</I>&gt;<i> &gt;&gt; way
</I>&gt;<i> &gt;&gt; of exposing this information?
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; I'm not entirely clear about what the use cases are for knowing if the  
</I>&gt;<i> &gt; camera is either user-view or environment-view.  It seems the more  
</I>&gt;<i> &gt; useful information to know is the orientation of the camera.  If the  
</I>&gt;<i> &gt; user switches cameras, that could also be handled by firing orientation  
</I>&gt;<i> &gt; events.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;&gt; Lachlan Hunt wrote:
</I>&gt;<i> &gt;&gt;&gt; There are some use cases for which it would be useful to know the
</I>&gt;<i> &gt;&gt;&gt; precise orientation of the camera, such as augmented reality
</I>&gt;<i> &gt;&gt;&gt; applications.  The camera orientation may be independent of the  
</I>&gt;<i> &gt;&gt;&gt; device's
</I>&gt;<i> &gt;&gt;&gt; orientation, and so the existing device orientation API may not be
</I>&gt;<i> &gt;&gt;&gt; sufficient.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; It seems like the best way to extend this would be to have the Device
</I>&gt;<i> &gt;&gt; Orientation API apply to GeneratedStream objects, either by just having
</I>&gt;<i> &gt;&gt; the events also fire on GeneratedStream objects, or by having the API be
</I>&gt;<i> &gt;&gt; based on a pull model rather than a push model and exposing an object on
</I>&gt;<i> &gt;&gt; GeneratedStream objects as well as Window objects.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; This could work.  But it would make more sense if there were an object  
</I>&gt;<i> &gt; representing the device itself, as in Rich's proposal, and for the  
</I>&gt;<i> &gt; events to be fired on that object instead of the stream.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;&gt; On Mon, 24 Jan 2011, Anne van Kesteren wrote:
</I>&gt;<i> &gt;&gt;&gt;
</I>&gt;<i> &gt;&gt;&gt; There is a plan of allowing direct assigning to IDL attributes besides
</I>&gt;<i> &gt;&gt;&gt; creating URLs.
</I>&gt;<i> &gt;&gt;&gt;
</I>&gt;<i> &gt;&gt;&gt; I.e. being able to do:
</I>&gt;<i> &gt;&gt;&gt;
</I>&gt;<i> &gt;&gt;&gt;   audio.src = blob
</I>&gt;<i> &gt;&gt;&gt;
</I>&gt;<i> &gt;&gt;&gt; (The src content attribute would then be something like  
</I>&gt;<i> &gt;&gt;&gt; &quot;about:objecturl&quot;.)
</I>&gt;<i> &gt;&gt;&gt;
</I>&gt;<i> &gt;&gt;&gt; I am not sure if that API should work differently from creating URLs  
</I>&gt;<i> &gt;&gt;&gt; and
</I>&gt;<i> &gt;&gt;&gt; assigning those, but we could consider it.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; Could you elaborate on this plan?
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; This is basically what Philip and I were discussing in the other thread  
</I>&gt;<i> &gt; yesterday, where we avoid the unnecessary overhead of creating a magic  
</I>&gt;<i> &gt; URL, and instead just assign the object directly to the src property.  
</I>&gt;<i> &gt; This lets the implementation handle all the magic transparently in the  
</I>&gt;<i> &gt; background, without bothering to expose a URLs string to the author.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; This is what we had implemented in our experimental implementation of  
</I>&gt;<i> &gt; the &lt;device&gt; element, and now getUserMedia.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; i.e.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; &lt;video&gt;&lt;/video&gt;
</I>&gt;<i> &gt; &lt;script&gt;
</I>&gt;<i> &gt; var v = document.querySelector(&quot;video&quot;);
</I>&gt;<i> &gt; navigator.getUserMedia(&quot;video&quot;, function(stream) {
</I>&gt;<i> &gt;    v.src = stream;
</I>&gt;<i> &gt;    v.play();
</I>&gt;<i> &gt; });
</I>&gt;<i> &gt; &lt;/script&gt;
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; The getter for v.src then returns &quot;about:streamurl&quot;.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; My understanding is that we don't really want to have to implement the  
</I>&gt;<i> &gt; create/revokeObjectURL() methods for this.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;&gt; On Wed, 16 Feb 2011, Anne van Kesteren wrote:
</I>&gt;<i> &gt;&gt;&gt; This is just a thought. Instead of acquiring a Stream object
</I>&gt;<i> &gt;&gt;&gt; asynchronously there always is one available showing transparent black
</I>&gt;<i> &gt;&gt;&gt; or some such. E.g. navigator.cameraStream. It also inherits from
</I>&gt;<i> &gt;&gt;&gt; EventTarget. Then on the Stream object you have methods to request
</I>&gt;<i> &gt;&gt;&gt; camera access which triggers some asynchronous UI. Once granted an
</I>&gt;<i> &gt;&gt;&gt; appropriately named event is dispatched on Stream indicating you now
</I>&gt;<i> &gt;&gt;&gt; have access to an actual stream. When the user decides it is enough and
</I>&gt;<i> &gt;&gt;&gt; turns of the camera (or something else happens) some other  
</I>&gt;<i> &gt;&gt;&gt; appropriately
</I>&gt;<i> &gt;&gt;&gt; named event is dispatched on Stream again turning it transparent black
</I>&gt;<i> &gt;&gt; again.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; This is a very interesting idea.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; This suggests that there would be a separate property available for the  
</I>&gt;<i> &gt; microphone, and any other input device.  This differs from the existing  
</I>&gt;<i> &gt; spec, which allowed a single stream to represent both audio and video.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;&gt; On Mon, 14 Mar 2011, Lachlan Hunt wrote:
</I>&gt;<i> &gt;&gt;&gt; The API includes both readystatechange event, as well as independent
</I>&gt;<i> &gt;&gt;&gt; events for play, paused and ended.  This redundancy is unnecessary.  
</I>&gt;<i> &gt;&gt;&gt; This
</I>&gt;<i> &gt;&gt;&gt; is also inconsistent with the design of the HTMLMediaElement API, which
</I>&gt;<i> &gt;&gt;&gt; does not include a readystatechange event in favour on separate events
</I>&gt;<i> &gt;&gt;&gt; only.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; I've dropped readystatechange.
</I>&gt;<i> &gt;&gt;
</I>&gt;<i> &gt;&gt; I expect to drop play and pause events if we move to the model described
</I>&gt;<i> &gt;&gt; above that pauses and resumes audio and video separately.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; It may still be useful to have events for this, if the event object had  
</I>&gt;<i> &gt; a property that indicated which type of stream it applied to, or if  
</I>&gt;<i> &gt; there were separate objects for both the audio and video streams.
</I>&gt;<i> &gt;
</I>&gt;<i> 
</I>&gt;<i> 
</I>
</PRE>






















<!--endarticle-->
<!--htdig_noindex-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="032326.html">[whatwg] Peer-to-peer communication, video conferencing, &lt;device&gt;, and related topics
</A></li>
	<LI>Next message: <A HREF="032417.html">[whatwg] PeerConnection, MediaStream, getUserMedia(),	and other feedback
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#32327">[ date ]</a>
              <a href="thread.html#32327">[ thread ]</a>
              <a href="subject.html#32327">[ subject ]</a>
              <a href="author.html#32327">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">More information about the whatwg
mailing list</a><br>
<!--/htdig_noindex-->
</body></html>
