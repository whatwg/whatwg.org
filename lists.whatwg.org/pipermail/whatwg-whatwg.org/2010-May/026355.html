<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [whatwg] Speech input element
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20Speech%20input%20element&In-Reply-To=%3CAANLkTimXfRGorcSaO9mhta1YzA2tU7jIAlkFR8jvlqI1%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="026351.html">
   <LINK REL="Next"  HREF="026376.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[whatwg] Speech input element</H1>
<!--htdig_noindex-->
    <B>Bjorn Bringert</B> 
    <A HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20Speech%20input%20element&In-Reply-To=%3CAANLkTimXfRGorcSaO9mhta1YzA2tU7jIAlkFR8jvlqI1%40mail.gmail.com%3E"
       TITLE="[whatwg] Speech input element">bringert at google.com
       </A><BR>
    <I>Tue May 18 01:52:53 PDT 2010</I>
    <P><UL>
        <LI>Previous message: <A HREF="026351.html">[whatwg] Speech input element
</A></li>
        <LI>Next message: <A HREF="026376.html">[whatwg] Speech input element
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#26355">[ date ]</a>
              <a href="thread.html#26355">[ thread ]</a>
              <a href="subject.html#26355">[ subject ]</a>
              <a href="author.html#26355">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--/htdig_noindex-->
<!--beginarticle-->
<PRE>On Tue, May 18, 2010 at 8:02 AM, Anne van Kesteren &lt;<A HREF="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">annevk at opera.com</A>&gt; wrote:
&gt;<i> On Mon, 17 May 2010 15:05:22 +0200, Bjorn Bringert &lt;<A HREF="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">bringert at google.com</A>&gt;
</I>&gt;<i> wrote:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Back in December there was a discussion about web APIs for speech
</I>&gt;&gt;<i> recognition and synthesis that saw a decent amount of interest
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> (<A HREF="http://lists.whatwg.org/pipermail/whatwg-whatwg.org/2009-December/thread.html#24281">http://lists.whatwg.org/pipermail/whatwg-whatwg.org/2009-December/thread.html#24281</A>).
</I>&gt;&gt;<i> Based on that discussion, we would like to propose a simple API for
</I>&gt;&gt;<i> speech recognition, using a new &lt;input type=&quot;speech&quot;&gt; element. An
</I>&gt;&gt;<i> informal spec of the new API, along with some sample apps and use
</I>&gt;&gt;<i> cases can be found at:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> <A HREF="http://docs.google.com/Doc?docid=0AaYxrITemjbxZGNmZzc5cHpfM2Ryajc5Zmhx&amp;hl=en.">http://docs.google.com/Doc?docid=0AaYxrITemjbxZGNmZzc5cHpfM2Ryajc5Zmhx&amp;hl=en.</A>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> It would be very helpful if you could take a look and share your
</I>&gt;&gt;<i> comments. Our next steps will be to implement the current design, get
</I>&gt;&gt;<i> some feedback from web developers, continue to tweak, and seek
</I>&gt;&gt;<i> standardization as soon it looks mature enough and/or other vendors
</I>&gt;&gt;<i> become interested in implementing it.
</I>&gt;<i>
</I>&gt;<i> I wonder how it relates to the &lt;device&gt; proposal already in the draft. In
</I>&gt;<i> theory that supports microphone input too.
</I>
It would be possible to implement speech recognition on top of a
microphone input API. The most obvious approach would be to use
&lt;device&gt; to get an audio stream, and send that audio stream to a
server (e.g. using WebSockets). The server runs a speech recognizer
and returns the results.

Advantages of the speech input element:

- Web app developers do not need to build and maintain a speech
recognition service.

- Implementations can choose to use client-side speech recognition.
This could give reduced network traffic and latency (but probably also
reduced recognition accuracy and language support). Implementations
could also use server-side recognition by default, switching to local
recognition in offline or low bandwidth situations.

- Using a general audio capture API would require APIs for things like
audio encoding and audio streaming. Judging from the past results of
specifying media features, this may be non-trivial. The speech input
element turns all audio processing concerns into implementation
details.

- Implementations can have special UI treatment for speech input,
which may be different from that for general audio capture.


Advantages of using a microphone API:

- Web app developers get complete control over the quality and
features of the speech recognizer. This is a moot point for most
developers though, since they do not have the resources to run their
own speech recognition service.

- Fewer features to implement in browsers (assuming that a microphone
API would be added anyway).

-- 
Bjorn Bringert
Google UK Limited, Registered Office: Belgrave House, 76 Buckingham
Palace Road, London, SW1W 9TQ
Registered in England Number: 3977902
</PRE>














































<!--endarticle-->
<!--htdig_noindex-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="026351.html">[whatwg] Speech input element
</A></li>
	<LI>Next message: <A HREF="026376.html">[whatwg] Speech input element
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#26355">[ date ]</a>
              <a href="thread.html#26355">[ thread ]</a>
              <a href="subject.html#26355">[ subject ]</a>
              <a href="author.html#26355">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">More information about the whatwg
mailing list</a><br>
<!--/htdig_noindex-->
</body></html>
