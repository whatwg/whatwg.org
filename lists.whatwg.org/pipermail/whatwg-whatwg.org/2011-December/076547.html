<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [whatwg] [encoding] utf-16
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20%5Bencoding%5D%20utf-16&In-Reply-To=%3C20111231073414704818.3dc0baad%40xn--mlform-iua.no%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="076546.html">
   <LINK REL="Next"  HREF="034265.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[whatwg] [encoding] utf-16</H1>
<!--htdig_noindex-->
    <B>Leif Halvard Silli</B> 
    <A HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20%5Bencoding%5D%20utf-16&In-Reply-To=%3C20111231073414704818.3dc0baad%40xn--mlform-iua.no%3E"
       TITLE="[whatwg] [encoding] utf-16">xn--mlform-iua at xn--mlform-iua.no
       </A><BR>
    <I>Fri Dec 30 22:34:14 PST 2011</I>
    <P><UL>
        <LI>Previous message: <A HREF="076546.html">[whatwg] [encoding] utf-16
</A></li>
        <LI>Next message: <A HREF="034265.html">[whatwg] [encoding]&#160;utf-16
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#76547">[ date ]</a>
              <a href="thread.html#76547">[ thread ]</a>
              <a href="subject.html#76547">[ subject ]</a>
              <a href="author.html#76547">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--/htdig_noindex-->
<!--beginarticle-->
<PRE>Anne van Kesteren  Fri, 30 Dec 2011 11:54:34 +0100
&gt;<i> On Fri, 30 Dec 2011 05:51:16 +0100, Leif Halvard Silli:
</I>&gt;&gt;<i> The Trident cache behaviour is a symptom of its over all UTF-16
</I>&gt;&gt;<i> behaviour: Apart from reading the BOM, it doesn't do any UTF-16
</I>&gt;&gt;<i> sniffing. I suspect that you want Opera/Firefox to become &quot;as bad&quot; at
</I>&gt;&gt;<i> 'getting' the UTF-16 encoding as Webkit/IE are? (Note that Webkit is
</I>&gt;&gt;<i> worse than IE - just to, once again, emphasize how difficult it is to
</I>&gt;&gt;<i> replicate IE.)
</I>&gt;<i> 
</I>&gt;<i> How is WebKit worse than IE?
</I>
For HTML: If HTTP says 'WINDOWS-1252' but the page is little-endian 
UTF-16 without the BOM, then IE will render the page as WINDOWS-1252, 
and this will actually work - at least in some circumstances ... Check: 
&lt;<A HREF="http://www.acsd.k12.sc.us/wwes/">http://www.acsd.k12.sc.us/wwes/</A>&gt;. (There could be other pages that IE 
handles, but which doesn't fall into this category.)

For XHTML: For 'nude' tests 
&lt;<A HREF="http://malform.no/testing/utf/#xml-table-1">http://malform.no/testing/utf/#xml-table-1</A>&gt;, then Webkit is worse than 
Trident &lt;<A HREF="http://malform.no/testing/utf/#xml-table-1-results">http://malform.no/testing/utf/#xml-table-1-results</A>&gt;. (Trident 
performs a variant of the sniffing described in XML 1.0, whereas Webkit 
does not sniff at all unless there is a XML prolog.)

&gt;<i> And why should there be UTF-16 sniffing?
</I>
FIRST: What is 'UTF-16 sniffing'? The BOM is a sniffing form.  The 
HTML5 character encoding *sniffing* algorithm covers UTF-16 as well. 
Should we single out UTF-16 sniffing as something that should not be 
sniffed?

     What do browser vendors think?

Based on the tests at &lt;<A HREF="http://malform.no/testing/utf/">http://malform.no/testing/utf/</A>&gt;, then it seems 
like IE performs no UTF-16 detection/sniffing beyond using HTTP, using 
the BOM and - as last resort - reading the META element (including the 
MS 'unicode' and MS 'unicodeFFFE' values - that Webkit also reads). 

But for HTML, then Trident - unlike Webkit - does not make use of the 
XML encoding declaration for detecting encoding: 
&lt;<A HREF="http://malform.no/testing/utf/#html-table-4">http://malform.no/testing/utf/#html-table-4</A>&gt;. And for HTML, then 
Trident - unlike Webkit - does not make use of the the XML prolog (no, 
not the encoding declaration) for sniffing the endianness of UTF-16 
files: &lt;<A HREF="http://malform.no/testing/utf/#html-table-9">http://malform.no/testing/utf/#html-table-9</A>&gt;.

Aligning with IE would mean that Opera, Mozilla and Webkit must 
'degenerate' their heuristics. Why would a vendor want to become less 
compatible with the Web?

&gt;&gt;<i> But is the little endian defaulting really important?
</I>&gt;&gt;<i> Over all, proper UTF-16 treatment (read: sniffing) on IE/WEbkit's part,
</I>&gt;&gt;<i> would probably improve the situation more.
</I>&gt;<i> 
</I>&gt;<i> You mean there are sites that only work in Gecko/Presto?
</I>
'Sites' is perhaps a big word - 'UTF-16' pages are often lone pages, it 
seems. But yes, obviously. E.g. big-endian UTF-16 labelled pages 
without a BOM. 

But, oops: It seems like Firefox does not use the META element anymore. 
It used to use the META element, in Firefox 3. But apparently stopped 
doing that - may be they misread the HTML5 algorithm ... Nevertheless, 
I have come across pages that work in Firefox/Opera but not Trident.

MS Word, which often make these pages, cane save both big and little 
endian.

&gt;&gt;<i> I know ... And it precisely therefore that it would have been an
</I>&gt;&gt;<i> advantage to, for the Web, focus on *requiring* the BOM for UTF-16.
</I>&gt;<i> 
</I>&gt;<i> It seems simpler to focus on promoting only UTF-8.
</I>
It seems simple enough say that the BOM must be used. Saying something 
like that is no different from saying that a certain range of 
WINDOWS-1252 must not be used, is it?

&gt;&gt;&gt;<i> Yeah, I'm going to file a new bug so we can reconsider although the  
</I>&gt;&gt;&gt;<i> octet sequence the various BOMs represent can have legitimate meanings  
</I>&gt;&gt;&gt;<i> in certain encodings,
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> You mean: In addition to the BOM meaning, I suppose.
</I>&gt;<i> 
</I>&gt;<i> No. In e.g. windows-1258 there is no BOM and FF FE simply means U+00FF  
</I>&gt;<i> U+20AB.
</I>
I think we have the same thing in mind. And btw, Google Search displays 
many such letters in UTF-16 encoded pages ... instead of displaying the 
content. Apparently, Google *fails* consider the BOM octets magic ... 
Or may be it is UTF-16-negative ...

&gt;&gt;&gt;<i> it seems in practice people use them for Unicode.
</I>&gt;&gt;&gt;<i> (Helped by the fact that Trident/WebKit behave this way of course.)
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> Don't forget the fact that Presto/Gecko do not move the BOM into the
</I>&gt;&gt;<i> &lt;body&gt; when you use UTF-16LE/BE, like they - per the spec of those
</I>&gt;&gt;<i> encodings - should do. See:
</I>&gt;&gt;<i> &lt;<A HREF="http://bugzilla.validator.nu/show_bug.cgi?id=890">http://bugzilla.validator.nu/show_bug.cgi?id=890</A>&gt;
</I>&gt;<i> 
</I>&gt;<i> Well yes, that's why I'm planning to define utf-16 more in line with  
</I>&gt;<i> implementations (and render the current text obsolete I suppose).
</I>
You don't need, for that reason, to follow a strategy that nullifies 
UTF-16LE/UTF-16BE. I outlined another strategy: Say that all HTML pages 
are interpreted as being 'UTF-16', even if they mis-labelled with the 
BOM-less UTF-16LE/UTF-16BE labels.
-- 
Leif H Silli

</PRE>

<!--endarticle-->
<!--htdig_noindex-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="076546.html">[whatwg] [encoding] utf-16
</A></li>
	<LI>Next message: <A HREF="034265.html">[whatwg] [encoding]&#160;utf-16
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#76547">[ date ]</a>
              <a href="thread.html#76547">[ thread ]</a>
              <a href="subject.html#76547">[ subject ]</a>
              <a href="author.html#76547">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">More information about the whatwg
mailing list</a><br>
<!--/htdig_noindex-->
</body></html>
