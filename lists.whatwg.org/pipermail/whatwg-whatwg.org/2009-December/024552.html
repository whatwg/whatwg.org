<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [whatwg] Web API for speech recognition and synthesis
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20Web%20API%20for%20speech%20recognition%20and%20synthesis&In-Reply-To=%3C1ac456d70912151225r67e3e18drb26f4e4253ee7e17%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="024501.html">
   <LINK REL="Next"  HREF="024553.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[whatwg] Web API for speech recognition and synthesis</H1>
<!--htdig_noindex-->
    <B>Bjorn Bringert</B> 
    <A HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20Web%20API%20for%20speech%20recognition%20and%20synthesis&In-Reply-To=%3C1ac456d70912151225r67e3e18drb26f4e4253ee7e17%40mail.gmail.com%3E"
       TITLE="[whatwg] Web API for speech recognition and synthesis">bringert at google.com
       </A><BR>
    <I>Tue Dec 15 12:25:54 PST 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="024501.html">[whatwg] Web API for speech recognition and synthesis
</A></li>
        <LI>Next message: <A HREF="024553.html">[whatwg] Web API for speech recognition and synthesis
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#24552">[ date ]</a>
              <a href="thread.html#24552">[ thread ]</a>
              <a href="subject.html#24552">[ subject ]</a>
              <a href="author.html#24552">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--/htdig_noindex-->
<!--beginarticle-->
<PRE>It seems like there is enough interest in speech to start developing
experimental implementations. There appear to be two general
directions that we could take:

- A general microphone API + streaming API + audio tag
  - Pro: Useful for non-speech recognition / synthesis applications.
           E.g. audio chat, sound recording.
  - Pro: Allows JavaScript libraries for third-party network speech services.
           E.g. an AJAX API for Google's speech services. Web app developers
           that don't have their own speech servers could use that.
  - Pro: Consistent recognition / synthesis user experience across
            user agents in the same web app.
  - Con: No support for on-device recognition / synthesis, only
            network services.
  - Con: Varying recognition / synthesis user experience across
            different web apps in a single user agent.
  - Con: Possibly higher overhead because the audio data needs to
            pass through JavaScript.
  - Con: Requires dealing with audio encodings, endpointing, buffer
            sizes etc in the microphone API.

- A speech-specific back-end neutral API
  - Pro: Simple API, basically just two methods: listen() and speak().
  - Pro: Can use local recognition / synthesis.
  - Pro: Consistent recognition / synthesis user experience across
           different web apps in a single user agent.
  - Con: Varying recognition / synthesis user experience across user
            agents in the same web app.
  - Con: Only works for speech, not general audio.

/Bjorn

On Sun, Dec 13, 2009 at 6:46 PM, Ian McGraw &lt;<A HREF="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">imcgraw at mit.edu</A>&gt; wrote:
&gt;<i> I'm new to this list, but as a speech-scientist and web developer, I wanted
</I>&gt;<i> to add my 2 cents. &#160;Personally, I believe the future of speech recognition
</I>&gt;<i> is in the cloud.
</I>&gt;<i> Here are two services which provide Javascript APIs for speech recognition
</I>&gt;<i> (and TTS) today:
</I>&gt;<i> <A HREF="http://wami.csail.mit.edu/">http://wami.csail.mit.edu/</A>
</I>&gt;<i> <A HREF="http://www.research.att.com/projects/SpeechMashup/index.html">http://www.research.att.com/projects/SpeechMashup/index.html</A>
</I>&gt;<i> Both of these are research systems, and as such they are really just
</I>&gt;<i> proof-of-concepts.
</I>&gt;<i> That said, Wami's JSONP-like implementation allows Quizlet.com to use speech
</I>&gt;<i> recognition today on a relatively large scale, with just a few lines of
</I>&gt;<i> Javascript code:
</I>&gt;<i> <A HREF="http://quizlet.com/voicetest/415/?scatter">http://quizlet.com/voicetest/415/?scatter</A>
</I>&gt;<i> Since there are a lot of Google folks on this list, I recommend you talk to
</I>&gt;<i> Alex Gruenstein (in your speech group) who was one of the lead developers of
</I>&gt;<i> WAMI while at MIT.
</I>&gt;<i> The major limitation we found when building the system was that we had to
</I>&gt;<i> develop a new audio controller for every client (Java for the desktop,
</I>&gt;<i> custom browsers for iPhone and Android). &#160;It would have been much simpler if
</I>&gt;<i> browsers came with standard microphone capture and audio streaming
</I>&gt;<i> capabilities.
</I>&gt;<i> -Ian
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On Sun, Dec 13, 2009 at 12:07 PM, Weston Ruter &lt;<A HREF="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">westonruter at gmail.com</A>&gt;
</I>&gt;<i> wrote:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I blogged yesterday about this topic (including a text-to-speech demo
</I>&gt;&gt;<i> using HTML5 Audio and Google Translate's TTS service); the more relevant
</I>&gt;&gt;<i> part for this thread:
</I>&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> I am really excited at the prospect of text-to-speech being made
</I>&gt;&gt;&gt;<i> available on
</I>&gt;&gt;&gt;<i> the Web! It's just too bad that fetching MP3s on an remote web service is
</I>&gt;&gt;&gt;<i> the
</I>&gt;&gt;&gt;<i> only standard way of doing so currently; modern operating systems all
</I>&gt;&gt;&gt;<i> have TTS
</I>&gt;&gt;&gt;<i> capabilities, so it's a shame that web apps and can't utilize them via
</I>&gt;&gt;&gt;<i> client-side scripting. I posted to the WHATWG mailing list about such a
</I>&gt;&gt;&gt;<i> Text-To-Speech (TTS) Web API for JavaScript, and I was directed to a
</I>&gt;&gt;&gt;<i> recent
</I>&gt;&gt;&gt;<i> thread about a Web API for speech recognition and synthesis.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Perhaps there is some momentum building here? Having TTS available in the
</I>&gt;&gt;&gt;<i> browser would boost accessibility for the seeing-impaired and improve
</I>&gt;&gt;&gt;<i> usability
</I>&gt;&gt;&gt;<i> for people on-the-go. TTS is just another technology that has
</I>&gt;&gt;&gt;<i> traditionally been
</I>&gt;&gt;&gt;<i> relegated to desktop applications, but as the open Web advances as the
</I>&gt;&gt;&gt;<i> preferred
</I>&gt;&gt;&gt;<i> platform for application development, it is an essential service to make
</I>&gt;&gt;&gt;<i> available (as with Geolocation API, Device API, etc.). And besides, I
</I>&gt;&gt;&gt;<i> want to
</I>&gt;&gt;&gt;<i> build TTS applications and my motto is: &quot;If it can't be done on the open
</I>&gt;&gt;&gt;<i> web,
</I>&gt;&gt;&gt;<i> it's not worth doing at all&quot;!
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> <A HREF="http://weston.ruter.net/projects/google-tts/">http://weston.ruter.net/projects/google-tts/</A>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Weston
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> On Fri, Dec 11, 2009 at 1:35 PM, Weston Ruter &lt;<A HREF="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">westonruter at gmail.com</A>&gt;
</I>&gt;&gt;<i> wrote:
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> I was just alerted about this thread from my post &quot;Text-To-Speech (TTS)
</I>&gt;&gt;&gt;<i> Web API for JavaScript&quot; at
</I>&gt;&gt;&gt;<i> &lt;<A HREF="http://lists.whatwg.org/htdig.cgi/whatwg-whatwg.org/2009-December/024453.html">http://lists.whatwg.org/htdig.cgi/whatwg-whatwg.org/2009-December/024453.html</A>&gt;.
</I>&gt;&gt;&gt;<i> Amazing how shared ideas like these seem to arise independently at the same
</I>&gt;&gt;&gt;<i> time.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> I have a use-case and an additional requirement, that the time indices be
</I>&gt;&gt;&gt;<i> made available for when each word is spoken in the TTS-generated audio:
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> I've been working on a web app which reads text in a web page,
</I>&gt;&gt;&gt;&gt;<i> highlighting each word as it is read. For this to be possible, a
</I>&gt;&gt;&gt;&gt;<i> Text-To-Speech API is needed which is able to:
</I>&gt;&gt;&gt;&gt;<i> (1) generate the speech audio from some text, and
</I>&gt;&gt;&gt;&gt;<i> (2) include the time indicies for when each of the words in the text is
</I>&gt;&gt;&gt;&gt;<i> spoken.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> I foresee that a TTS API should integrate closely with the HTML5 Audio
</I>&gt;&gt;&gt;<i> API. For example, invoking a call to the API could return a &quot;TTS&quot; object
</I>&gt;&gt;&gt;<i> which has an instance of Audio, whose interface could be used to navigate
</I>&gt;&gt;&gt;<i> through the TTS output. For example:
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> var tts = new TextToSpeech(&quot;Hello, World!&quot;);
</I>&gt;&gt;&gt;<i> tts.audio.addEventListener(&quot;canplaythrough&quot;, function(e){
</I>&gt;&gt;&gt;<i> &#160;&#160;&#160; //tts.indices == [{startTime:0, endTime:500, text:&quot;Hello&quot;},
</I>&gt;&gt;&gt;<i> {startTime:500, endTime:1000, text:&quot;World&quot;}]
</I>&gt;&gt;&gt;<i> }, false);
</I>&gt;&gt;&gt;<i> tts.read(); //invokes tts.audio.play
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> What would be even cooler, is if the parameter passed to the TextToSpeech
</I>&gt;&gt;&gt;<i> constructor could be an Element or TextNode, and the indices would then
</I>&gt;&gt;&gt;<i> include a DOM Range in addition to the &quot;text&quot; property. A flag could also be
</I>&gt;&gt;&gt;<i> set which would result in each of these DOM ranges to be selected when it is
</I>&gt;&gt;&gt;<i> read. For example:
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> var tts = new TextToSpeech(document.querySelector(&quot;article&quot;));
</I>&gt;&gt;&gt;<i> tts.selectRangesOnRead = true;
</I>&gt;&gt;&gt;<i> tts.audio.addEventListener(&quot;canplaythrough&quot;, function(e){
</I>&gt;&gt;&gt;<i> &#160;&#160;&#160; /*
</I>&gt;&gt;&gt;<i> &#160;&#160;&#160; tts.indices == [
</I>&gt;&gt;&gt;<i> &#160;&#160;&#160;&#160;&#160;&#160;&#160; {startTime:0, endTime:500, text:&quot;Hello&quot;, range:Range},
</I>&gt;&gt;&gt;<i> &#160;&#160;&#160;&#160;&#160;&#160;&#160; {startTime:500, endTime:1000, text:&quot;World&quot;, range:Range}
</I>&gt;&gt;&gt;<i> &#160;&#160;&#160; ]
</I>&gt;&gt;&gt;<i> &#160;&#160;&#160; */
</I>&gt;&gt;&gt;<i> }, false);
</I>&gt;&gt;&gt;<i> tts.read();
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> In addition to the events fired by the Audio API, more events could be
</I>&gt;&gt;&gt;<i> fired when reading TTS, such as a &quot;readrange&quot; event whose event object would
</I>&gt;&gt;&gt;<i> include the index (startTime, endTime, text, range) for the range currently
</I>&gt;&gt;&gt;<i> being spoken. Such functionality would make the ability to &quot;read along&quot; with
</I>&gt;&gt;&gt;<i> the text trivial.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> What do you think?
</I>&gt;&gt;&gt;<i> Weston
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> On Thu, Dec 3, 2009 at 4:06 AM, Bjorn Bringert &lt;<A HREF="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">bringert at google.com</A>&gt;
</I>&gt;&gt;&gt;<i> wrote:
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> On Wed, Dec 2, 2009 at 10:20 PM, Jonas Sicking &lt;<A HREF="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">jonas at sicking.cc</A>&gt; wrote:
</I>&gt;&gt;&gt;&gt;<i> &gt; On Wed, Dec 2, 2009 at 11:17 AM, Bjorn Bringert &lt;<A HREF="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">bringert at google.com</A>&gt;
</I>&gt;&gt;&gt;&gt;<i> &gt; wrote:
</I>&gt;&gt;&gt;&gt;<i> &gt;&gt; I agree that being able to capture and upload audio to a server would
</I>&gt;&gt;&gt;&gt;<i> &gt;&gt; be useful for a lot of applications, and it could be used to do
</I>&gt;&gt;&gt;&gt;<i> &gt;&gt; speech
</I>&gt;&gt;&gt;&gt;<i> &gt;&gt; recognition. However, for a web app developer who just wants to
</I>&gt;&gt;&gt;&gt;<i> &gt;&gt; develop an application that uses speech input and/or output, it
</I>&gt;&gt;&gt;&gt;<i> &gt;&gt; doesn't seem very convenient, since it requires server-side
</I>&gt;&gt;&gt;&gt;<i> &gt;&gt; infrastructure that is very costly to develop and run. A
</I>&gt;&gt;&gt;&gt;<i> &gt;&gt; speech-specific API in the browser gives browser implementors the
</I>&gt;&gt;&gt;&gt;<i> &gt;&gt; option to use on-device speech services provided by the OS, or
</I>&gt;&gt;&gt;&gt;<i> &gt;&gt; server-side speech synthesis/recognition.
</I>&gt;&gt;&gt;&gt;<i> &gt;
</I>&gt;&gt;&gt;&gt;<i> &gt; Again, it would help a lot of you could provide use cases and
</I>&gt;&gt;&gt;&gt;<i> &gt; requirements. This helps both with designing an API, as well as
</I>&gt;&gt;&gt;&gt;<i> &gt; evaluating if the use cases are common enough that a dedicated API is
</I>&gt;&gt;&gt;&gt;<i> &gt; the best solution.
</I>&gt;&gt;&gt;&gt;<i> &gt;
</I>&gt;&gt;&gt;&gt;<i> &gt; / Jonas
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> I'm mostly thinking about speech web apps for mobile devices. I think
</I>&gt;&gt;&gt;&gt;<i> that's where speech makes most sense as an input and output method,
</I>&gt;&gt;&gt;&gt;<i> because of the poor keyboards, small screens, and frequent hands/eyes
</I>&gt;&gt;&gt;&gt;<i> busy situations (e.g. while driving). Accessibility is the other big
</I>&gt;&gt;&gt;&gt;<i> reason for using speech.
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> Some ideas for use cases:
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> - Search by speaking a query
</I>&gt;&gt;&gt;&gt;<i> - Speech-to-speech translation
</I>&gt;&gt;&gt;&gt;<i> - Voice Dialing (could open a tel: URI to actually make the call)
</I>&gt;&gt;&gt;&gt;<i> - Dialog systems (e.g. the canonical pizza ordering system)
</I>&gt;&gt;&gt;&gt;<i> - Lightweight JavaScript browser extensions (e.g. Greasemonkey /
</I>&gt;&gt;&gt;&gt;<i> Chrome extensions) for using speech with any web site, e.g, for
</I>&gt;&gt;&gt;&gt;<i> accessibility.
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> Requirements:
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> - Web app developer side:
</I>&gt;&gt;&gt;&gt;<i> &#160; - Allows both speech recognition and synthesis.
</I>&gt;&gt;&gt;&gt;<i> &#160; - Easy to use API. Makes simple things easy and advanced things
</I>&gt;&gt;&gt;&gt;<i> possible.
</I>&gt;&gt;&gt;&gt;<i> &#160; - Doesn't require web app developer to develop / run his own speech
</I>&gt;&gt;&gt;&gt;<i> recognition / synthesis servers.
</I>&gt;&gt;&gt;&gt;<i> &#160; - (Natural) language-neutral API.
</I>&gt;&gt;&gt;&gt;<i> &#160; - Allows developer-defined application specific grammars / language
</I>&gt;&gt;&gt;&gt;<i> models.
</I>&gt;&gt;&gt;&gt;<i> &#160; - Allows multilingual applications.
</I>&gt;&gt;&gt;&gt;<i> &#160; - Allows easy localization of speech apps.
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> - Implementor side:
</I>&gt;&gt;&gt;&gt;<i> &#160; - Easy enough to implement that it can get wide adoption in browsers.
</I>&gt;&gt;&gt;&gt;<i> &#160; - Allows implementor to use either client-side or server-side
</I>&gt;&gt;&gt;&gt;<i> recognition and synthesis.
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> --
</I>&gt;&gt;&gt;&gt;<i> Bjorn Bringert
</I>&gt;&gt;&gt;&gt;<i> Google UK Limited, Registered Office: Belgrave House, 76 Buckingham
</I>&gt;&gt;&gt;&gt;<i> Palace Road, London, SW1W 9TQ
</I>&gt;&gt;&gt;&gt;<i> Registered in England Number: 3977902
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>


-- 
Bjorn Bringert
Google UK Limited, Registered Office: Belgrave House, 76 Buckingham
Palace Road, London, SW1W 9TQ
Registered in England Number: 3977902
</PRE>


<!--endarticle-->
<!--htdig_noindex-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="024501.html">[whatwg] Web API for speech recognition and synthesis
</A></li>
	<LI>Next message: <A HREF="024553.html">[whatwg] Web API for speech recognition and synthesis
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#24552">[ date ]</a>
              <a href="thread.html#24552">[ thread ]</a>
              <a href="subject.html#24552">[ subject ]</a>
              <a href="author.html#24552">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">More information about the whatwg
mailing list</a><br>
<!--/htdig_noindex-->
</body></html>
