<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [whatwg] PeerConnection feedback
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20PeerConnection%20feedback&In-Reply-To=%3CBANLkTi%3Do3or93Hg-0tHamFYha6QpriTcgg%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="031213.html">
   <LINK REL="Next"  HREF="031232.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[whatwg] PeerConnection feedback</H1>
<!--htdig_noindex-->
    <B>Justin Uberti</B> 
    <A HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20PeerConnection%20feedback&In-Reply-To=%3CBANLkTi%3Do3or93Hg-0tHamFYha6QpriTcgg%40mail.gmail.com%3E"
       TITLE="[whatwg] PeerConnection feedback">juberti at google.com
       </A><BR>
    <I>Mon Apr 11 23:17:30 PDT 2011</I>
    <P><UL>
        <LI>Previous message: <A HREF="031213.html">[whatwg]  PeerConnection feedback
</A></li>
        <LI>Next message: <A HREF="031232.html">[whatwg] PeerConnection feedback
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#31217">[ date ]</a>
              <a href="thread.html#31217">[ thread ]</a>
              <a href="subject.html#31217">[ subject ]</a>
              <a href="author.html#31217">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--/htdig_noindex-->
<!--beginarticle-->
<PRE>CIL

On Mon, Apr 11, 2011 at 7:09 PM, Ian Hickson &lt;<A HREF="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">ian at hixie.ch</A>&gt; wrote:

&gt;<i> On Tue, 29 Mar 2011, Robert O'Callahan wrote:
</I>&gt;<i> &gt; Ian Hickson wrote:
</I>&gt;<i> &gt; &gt;
</I>&gt;<i> &gt; &gt; I agree that (on the long term) we should support stream filters on
</I>&gt;<i> &gt; &gt; streams, but I'm not sure I understand &lt;video&gt;'s role in this.
</I>&gt;<i> &gt; &gt; Wouldn't it be more efficient to have something that takes a Stream on
</I>&gt;<i> &gt; &gt; one side and outputs a Stream on the other, possibly running some
</I>&gt;<i> &gt; &gt; native code or JS in the middle?
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; We could.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; I'm trying to figure out how this is going to fit in with audio APIs.
</I>&gt;<i> &gt; Chris Rogers from Google is proposing a graph-based audio API to the W3C
</I>&gt;<i> &gt; Audio incubator group which would overlap considerably with a Stream
</I>&gt;<i> &gt; processing API like you're suggesting (although in his proposal
</I>&gt;<i> &gt; processing nodes, not streams, are first-class).
</I>&gt;<i>
</I>&gt;<i> Indeed. I think it would make sense to have nodes in this graph that could
</I>&gt;<i> take Streams as input, or output the resulting data as Streams.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> &gt; A fundamental problem here is that HTML media elements have the
</I>&gt;<i> &gt; functionality of both sources and sinks.
</I>&gt;<i>
</I>&gt;<i> Indeed. Unfortunately, at the time that we were designing &lt;video&gt;, the
</I>&gt;<i> later needs of multitrack video and video conferencing were not completely
</I>&gt;<i> clear. If we could go back, I think it would make sense to split the part
</I>&gt;<i> of &lt;video&gt; that does network traffic and the part of &lt;video&gt; that does
</I>&gt;<i> rendering and UI control from each other, if only to make it possible
</I>&gt;<i> now to have them be split further for video conferencing and multitrack.
</I>&gt;<i> Sadly, that's not really an option.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> &gt; You want to see &lt;video&gt; and &lt;audio&gt; only as sinks which accept streams.
</I>&gt;<i> &gt; But in that case, if we create an audio processing API using Streams,
</I>&gt;<i> &gt; we'll need a way to download stream data for processing that doesn't use
</I>&gt;<i> &gt; &lt;audio&gt; and &lt;video&gt;, which means we'll need to replicate &lt;src&gt; elements,
</I>&gt;<i> &gt; the type attribute, networkstates, readystates, possibly the 'loop'
</I>&gt;<i> &gt; attribute... should we introduce a new object or element that provides
</I>&gt;<i> &gt; those APIs? How much can be shared with &lt;video&gt; and &lt;audio&gt;? Should we
</I>&gt;<i> &gt; be trying to share? (In Chris Rogers' proposal, &lt;audio&gt; elements are
</I>&gt;<i> &gt; used as sources, not sinks.)
</I>&gt;<i>
</I>&gt;<i> I think at this point we should probably just make media elements (&lt;video&gt;
</I>&gt;<i> and &lt;audio&gt;) support being used both as sources and as sinks. They'll just
</I>&gt;<i> be a little overweight when used just for one of those purposes.
</I>&gt;<i>
</I>&gt;<i> Basically I'm suggesting viewing media elements like this:
</I>&gt;<i>
</I>&gt;<i>   URL to network resource
</I>&gt;<i>   URL to Stream object
</I>&gt;<i>   URL to Blob object
</I>&gt;<i>   |
</I>&gt;<i>   |   ----------------------------
</I>&gt;<i>   +-&gt; :SINK                SOURCE: -+
</I>&gt;<i>       ------------. T .-----------  |
</I>&gt;<i>                   |   |             |
</I>&gt;<i>                   |   |            Input for
</I>&gt;<i>                   |   |            Audio API
</I>&gt;<i>                   |   |
</I>&gt;<i>                   \   /
</I>&gt;<i>                    \ /
</I>&gt;<i>                     V
</I>&gt;<i>                  DISPLAY
</I>&gt;<i>                    AND
</I>&gt;<i>                SOUND BOARD
</I>&gt;<i>
</I>&gt;<i> It's a source that happens to have built-in monitor output. Or a sink that
</I>&gt;<i> happens to have a monitor output port. Depending on how you want to see it.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On Tue, 29 Mar 2011, Harald Alvestrand wrote:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; A lot of firewalls (including Google's, I believe) drop the subsequent
</I>&gt;<i> &gt; part of fragmented UDP packets, because it's impossible to apply
</I>&gt;<i> &gt; firewall rules to fragments without keeping track of all fragmented UDP
</I>&gt;<i> &gt; packets that are in the process of being transmitted (and keeping track
</I>&gt;<i> &gt; would open the firewalls to an obvious resource exhaustion attack).
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; This has made UDP packets larger than the MTU pretty useless.
</I>&gt;<i>
</I>&gt;<i> So I guess the question is do we want to limit the input to a fixed value
</I>&gt;<i> that is the lowest used MTU (576 bytes per IPv4), or dynamically and
</I>&gt;<i> regularly determine what the lowest possible MTU is?
</I>&gt;<i>
</I>&gt;<i> The former has a major advantage: if an application works in one
</I>&gt;<i> environment, you know it'll work elsewhere, because the maximum packet
</I>&gt;<i> size won't change. This is a erious concern on the Web, where authors tend
</I>&gt;<i> to do limited testing and thus often fail to handle rare edge cases well.
</I>&gt;<i>
</I>&gt;<i> The latter has a major disadvantage: the path MTU might change, meaning we
</I>&gt;<i> might start dropping data if we don't keep trying to determine the Path
</I>&gt;<i> MTU. Also, it's really hard to determine the Path MTU in practice.
</I>&gt;<i>
</I>&gt;<i> For now I've gone with the IPv4 &quot;minimum maximum&quot; of 576 minus overhead,
</I>&gt;<i> leaving 504 bytes for user data per packet. It seems small, but I don't
</I>&gt;<i> know how much data people normally send along these low-latency unreliable
</I>&gt;<i> channels.
</I>&gt;<i>
</I>&gt;<i> However, if people want to instead have the minimum be dynamically
</I>&gt;<i> determined, I'm open to that too. I think the best way to approach that
</I>&gt;<i> would be to have UAs implement it as an experimental extension at first,
</I>&gt;<i> and for us to get implementation experience on how well it works. If
</I>&gt;<i> anyone is interested in doing that I'm happy to work with them to work out
</I>&gt;<i> a way to do this that doesn't interfere with UAs that don't yet implement
</I>&gt;<i> that extension.
</I>&gt;<i>
</I>&gt;<i>
</I>In practice, applications assume that the minimum MTU is 1280 (the minimum
IPv6 MTU), and limit payloads to about 1200 bytes so that with framing they
will fit into a 1280-byte MTU. Going down to 576 would significantly
increase the packetization overhead.


&gt;<i> On Tue, 29 Mar 2011, Harald Alvestrand wrote:
</I>&gt;<i> &gt; On 03/29/11 03:00, Ian Hickson wrote:
</I>&gt;<i> &gt; &gt; On Wed, 23 Mar 2011, Harald Alvestrand wrote:
</I>&gt;<i> &gt; &gt; &gt; &gt;
</I>&gt;<i> &gt; &gt; &gt; &gt; Is there really an advantage to not using SRTP and reusing the RTP
</I>&gt;<i> &gt; &gt; &gt; &gt; format for the data messages?
</I>&gt;<i> &gt; &gt;
</I>&gt;<i> &gt; &gt; Could you elaborate on how (S)RTP would be used for this? I'm all in
</I>&gt;<i> &gt; &gt; favour of defering as much of this to existing protocols as possible,
</I>&gt;<i> &gt; &gt; but RTP seemed like massive overkill for sending game status packets.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; If &quot;data&quot; was defined as an RTP codec (&quot;application/packets?&quot;), SRTP
</I>&gt;<i> &gt; could be applied to the packets.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; It would impose a 12-byte header in front of the packet and the
</I>&gt;<i> &gt; recommended authentication tag at the end, but would ensure that we
</I>&gt;<i> &gt; could use exactly the same procedure for key exchange
</I>&gt;<i>
</I>&gt;<i> We already use SDP for key exchange for the data stream.
</I>&gt;<i>
</I>


&gt;<i>
</I>&gt;<i> &gt; multiplexing of multiple data streams on the same channel using SSRC,
</I>&gt;<i>
</I>&gt;<i> I don't follow. What benefit would that have?
</I>&gt;<i>
</I>
If you are in a conference that has 10 participants, you don't want to have
to set up a new transport for each participant. Instead, SSRC provides an
excellent way to multiplex multiple media streams over a single RTP session
(and network transport).

&gt;<i>
</I>&gt;<i>
</I>&gt;<i> &gt; and procedures for identifying the stream in SDP (if we continue to use
</I>&gt;<i> &gt; SDP) - I believe SDP implicitly assumes that all the streams it
</I>&gt;<i> &gt; describes are RTP streams.
</I>&gt;<i>
</I>&gt;<i> That doesn't seem to be the case, but I could be misinterpreting SDP.
</I>&gt;<i> Currently, the HTML spec includes instructions on how to identify the
</I>&gt;<i> stream in SDP; if those instructions are meaningless due to a
</I>&gt;<i> misunderstanding of SDP then we should fix it (and in that case, it might
</I>&gt;<i> indeed make a lot of sense to use RTP to carry this data).
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> &gt; I've been told that defining RTP packetization formats for a codec needs
</I>&gt;<i> &gt; to be done carefully, so I don't think this is a full specification, but
</I>&gt;<i> &gt; it seems that the overhead of doing so is on the same order of magnitude
</I>&gt;<i> &gt; as the currently proposed solution, and the security properties then
</I>&gt;<i> &gt; become very similar to the properties for media streams.
</I>&gt;<i>
</I>&gt;<i> There are very big differences in the security considerations for media
</I>&gt;<i> data and the security considerations for the data stream. In particular,
</I>&gt;<i> the media data can't be generated by the author in any meaningful way,
</I>&gt;<i> whereas the data is entirely under author control. I don't think it is
</I>&gt;<i> safe to assume that the security properties that we have for media streams
</I>&gt;<i> necessarily work for data streams.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On Tue, 29 Mar 2011, Harald Alvestrand wrote:
</I>&gt;<i> &gt; &gt; &gt; &gt;
</I>&gt;<i> &gt; &gt; &gt; &gt; Recording any of these requires much more specification than just
</I>&gt;<i> &gt; &gt; &gt; &gt; &quot;record here&quot;.
</I>&gt;<i> &gt; &gt;
</I>&gt;<i> &gt; &gt; Could you elaborate on what else needs specifying?
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; One thing I remember from an API design talk I viewed: &quot;An ability to
</I>&gt;<i> &gt; record to a file means that the file format is part of your API.&quot;
</I>&gt;<i>
</I>&gt;<i> Indeed.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> &gt; For instance, for audio recording, it's likely that you want control
</I>&gt;<i> &gt; over whether the resulting file is in Ogg Vorbis format or in MP3
</I>&gt;<i> &gt; format; for video, it's likely that you may want to specify that it will
</I>&gt;<i> &gt; be stored using the VP8 video codec, the Vorbis audio codec and the
</I>&gt;<i> &gt; Matroska container format. These desires have to be communicated to the
</I>&gt;<i> &gt; underlying audio/video engine, so that the proper transforms can be
</I>&gt;<i> &gt; inserted into the processing stream
</I>&gt;<i>
</I>&gt;<i> Yes, we will absolutely need to add these features in due course. Exactly
</I>&gt;<i> what we should add is something we have to determine from implementation
</I>&gt;<i> experience.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> &gt; and I think they have to be communicated across this interface; since
</I>&gt;<i> &gt; the output of these operations is a blob without any inherent type
</I>&gt;<i> &gt; information, the caller has to already know which format the media is
</I>&gt;<i> &gt; in.
</I>&gt;<i>
</I>&gt;<i> Depending on the use case and on implementation trajectories, this isn't a
</I>&gt;<i> given. For example, if all UAs end up implementing one of two
</I>&gt;<i> codec/container combinations and we don't expose any controls, it may be
</I>&gt;<i> that the first few bytes of the output file are in practice enough to
</I>&gt;<i> fully identify the format used.
</I>&gt;<i>
</I>&gt;<i> Note also that Blob does have a MIME type, so even without looking at the
</I>&gt;<i> data itself, or at the UA string, it may be possible to get a general idea
</I>&gt;<i> of the container and maybe even codecs.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On Wed, 30 Mar 2011, Stefan H&#65533;kansson LK wrote:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; This is absolutely correct, and it is not only about codecs or container
</I>&gt;<i> &gt; formats. Maybe you need to supply info like audio sampling rate, video
</I>&gt;<i> &gt; frame rate, video resolution, ... There was an input on this already
</I>&gt;<i> &gt; last November:
</I>&gt;<i> &gt;
</I>&gt;<i> <A HREF="http://lists.whatwg.org/htdig.cgi/whatwg-whatwg.org/2010-November/029069.html">http://lists.whatwg.org/htdig.cgi/whatwg-whatwg.org/2010-November/029069.html</A>
</I>&gt;<i>
</I>&gt;<i> Indeed. The situation hasn't changed since then:
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> <A HREF="http://lists.whatwg.org/htdig.cgi/whatwg-whatwg.org/2011-February/030484.html">http://lists.whatwg.org/htdig.cgi/whatwg-whatwg.org/2011-February/030484.html</A>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On Tue, 29 Mar 2011, Stefan H&#65533;kansson LK wrote:
</I>&gt;<i> &gt; &gt; &gt; &gt; &gt; The web application must be able to define the media format to
</I>&gt;<i> &gt; &gt; &gt; &gt; &gt; be used for the streams sent to a peer.
</I>&gt;<i> &gt; &gt; &gt; &gt;
</I>&gt;<i> &gt; &gt; &gt; &gt; Shouldn't this be automatic and renegotiated dynamically via SDP
</I>&gt;<i> &gt; &gt; &gt; &gt; offer/answer?
</I>&gt;<i> &gt; &gt; &gt;
</I>&gt;<i> &gt; &gt; &gt; Yes, this should be (re)negotiated via SDP, but what is unclear is
</I>&gt;<i> &gt; &gt; &gt; how the SDP is populated based on the application's preferences.
</I>&gt;<i> &gt; &gt;
</I>&gt;<i> &gt; &gt; Why would the Web application have any say on this? Surely the user
</I>&gt;<i> &gt; &gt; agent is in a better position to know what to negotiate, since it will
</I>&gt;<i> &gt; &gt; be doing the encoding and decoding itself.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; The best format of the coded media being streamed from UA a to UA b
</I>&gt;<i> &gt; depends on a lot of factors. An obvious one is that the codec used is
</I>&gt;<i> &gt; supported by both UAs.... As you say much of it can be handled without
</I>&gt;<i> &gt; any involvement from the application.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; But let's say that the app in UA a does &quot;addStream&quot;. The application in
</I>&gt;<i> &gt; UA b (the same application as in UA a) has two &lt;video&gt; elements, one
</I>&gt;<i> &gt; using a large display size, one using a small size. The UAs don't know
</I>&gt;<i> &gt; in which element the stream will be rendered at this stage (that will be
</I>&gt;<i> &gt; known first when the app in UA b connects the stream to one of the
</I>&gt;<i> &gt; elements at &quot;onaddstream&quot;), so I don't understand how the UAs can select
</I>&gt;<i> &gt; a suitable video resolution without the application giving some input.
</I>&gt;<i> &gt; (Once the stream is being rendered in an element the situation is
</I>&gt;<i> &gt; different - then UA b has knowledge about the rendering and could
</I>&gt;<i> &gt; somehow inform UA a.)
</I>&gt;<i>
</I>&gt;<i> I had assumed that the video would at first be sent with some more or less
</I>&gt;<i> arbitrary dimensions (maybe the native ones), and that the receiving UA
</I>&gt;<i> would then renegotiate the dimensions once the stream was being displayed
</I>&gt;<i> somewhere. Since the page can let the user change the &lt;video&gt; size
</I>&gt;<i> dynamically, it seems the UA would likely need to be able to do that kind
</I>&gt;<i> of dynamic update anyway.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On Thu, 31 Mar 2011, Lachlan Hunt wrote:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; When getUserMedia() is invoked with unknown options, the spec currently
</I>&gt;<i> &gt; implicitly requires a PERMISSION_DENIED error to be thrown.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; e.g. navigator.getUserMedia(&quot;foo&quot;);
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; In this case, the option for &quot;foo&quot; is unknown.  Presumably, this would
</I>&gt;<i> &gt; fall under platform limitations, and would thus jump from step 11 to the
</I>&gt;<i> &gt; failure case, and throw a permission denied error.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; We are wondering if this is the most ideal error to throw in this case,
</I>&gt;<i> &gt; as opposed to introducing a more logical NOT_SUPPORTED error, and if it
</I>&gt;<i> &gt; might be useful to authors to distinguish these cases?
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; We assume, however, that if the author requests &quot;audio,foo&quot;, and the
</I>&gt;<i> &gt; user grants access to audio, then the success callback would be invoked,
</I>&gt;<i> &gt; despite the unknown option for &quot;foo&quot;.
</I>&gt;<i>
</I>&gt;<i> Good point. I've updated the spec to fire NOT_SUPPORTED_ERR if there's no
</I>&gt;<i> known value.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On Fri, 8 Apr 2011, Harald Alvestrand wrote:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; The current (April 8) version of section 9.4 says that the config string
</I>&gt;<i> for a
</I>&gt;<i> &gt; PeerConnection object is this:
</I>&gt;<i> &gt; ---------------------------
</I>&gt;<i> &gt; The allowed formats for this string are:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; &quot;TYPE 203.0.113.2:3478&quot;
</I>&gt;<i> &gt; Indicates a specific IP address and port for the server.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; &quot;TYPE relay.example.net:3478&quot;
</I>&gt;<i> &gt; Indicates a specific host and port for the server; the user agent will
</I>&gt;<i> look up
</I>&gt;<i> &gt; the IP address in DNS.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; &quot;TYPE example.net&quot;
</I>&gt;<i> &gt; Indicates a specific domain for the server; the user agent will look up
</I>&gt;<i> the IP
</I>&gt;<i> &gt; address and port in DNS.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; The &quot;TYPE&quot; is one of:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; STUN
</I>&gt;<i> &gt; Indicates a STUN server
</I>&gt;<i> &gt; STUNS
</I>&gt;<i> &gt; Indicates a STUN server that is to be contacted using a TLS session.
</I>&gt;<i> &gt; TURN
</I>&gt;<i> &gt; Indicates a TURN server
</I>&gt;<i> &gt; TURNS
</I>&gt;<i> &gt; Indicates a TURN server that is to be contacted using a TLS session.
</I>&gt;<i> &gt; -------------------------------
</I>&gt;<i> &gt; I believe this is insufficient, for a number of reasons:
</I>&gt;<i> &gt; - For future extensibility, new forms of init data needs to be passed
</I>&gt;<i> without
</I>&gt;<i> &gt; invalidating old implementations. This indicates that a serialized JSON
</I>&gt;<i> object
</I>&gt;<i> &gt; with a few keys of defined meaning is a better basic structure than a
</I>&gt;<i> format
</I>&gt;<i> &gt; string with no format identifier.
</I>&gt;<i>
</I>&gt;<i> The format is already defined in a forward-compatible manner.
</I>&gt;<i> Specifically, UAs are currently required to ignore everything past the
</I>&gt;<i> first line feed character. In a future version, we could extend this API
</I>&gt;<i> by simply including additional data after the linefeed.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> &gt; - For use with STUN and TURN, we need to support the case where we need a
</I>&gt;<i> STUN
</I>&gt;<i> &gt; server and a TURN server, and they're different.
</I>&gt;<i>
</I>&gt;<i> TURN servers are STUN servers, at least according to the relevant RFCs, as
</I>&gt;<i> far as I can tell. Can you elaborate on which TURN servers do not
</I>&gt;<i> implement STUN, or explain the use cases for having different TURN and
</I>&gt;<i> STUN servers? This is an area where I am most definitely not an expert, so
</I>&gt;<i> any information here would be quite helpful.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> &gt; - The method of DNS lookup is not specified. In particular, it is not
</I>&gt;<i> &gt; specified whether SRV records are looked up or not.
</I>&gt;<i>
</I>&gt;<i> This seems to be entirely specified. Please ensure that you are reading
</I>&gt;<i> the normative conformance criteria for user agents, and not the
</I>&gt;<i> non-normative authoring advice, which is only a brief overview.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> &gt; - We have no evaluation that shows that we'll never need the unencrypted
</I>&gt;<i> &gt; TCP version of STUN or TURN, or that we need to support the encrypted
</I>&gt;<i> &gt; STUN version. We should either support all formats that the spec can
</I>&gt;<i> &gt; generate, or we should get a reasonable survey of implementors on what
</I>&gt;<i> &gt; they think is needed.
</I>&gt;<i>
</I>&gt;<i> If anyone has any data on this, that would indeed be quite useful.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On Fri, 8 Apr 2011, Harald Alvestrand wrote:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; BTW, I haven't been on this list that long... if anyone has advice on
</I>&gt;<i> &gt; whether such discussions are better as buganizer threads or as whatwg
</I>&gt;<i> &gt; mailing list threads, please give it!
</I>&gt;<i>
</I>&gt;<i> Discussion is best on the mailing list. In general Bugzilla is best for
</I>&gt;<i> straight-forward bugs rather than design discussions.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On Fri, 8 Apr 2011, Glenn Maynard wrote:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; FWIW, I thought the block-of-text configuration string was peculiar and
</I>&gt;<i> &gt; unlike anything else in the platform.  I agree that using a
</I>&gt;<i> &gt; configuration object (of some kind) makes more sense.
</I>&gt;<i>
</I>&gt;<i> An object wouldn't work very well as it would add additional steps in the
</I>&gt;<i> case where someone just wants to transmit the configuration information to
</I>&gt;<i> the client as data. Using JSON strings as input as Harald suggested could
</I>&gt;<i> work, but seems overly verbose for such a simple data.
</I>&gt;<i>
</I>
I have a feeling that this configuration information will only start off
simple.

&gt;<i>
</I>&gt;<i> --
</I>&gt;<i> Ian Hickson               U+1047E                )\._.,--....,'``.    fL
</I>&gt;<i> <A HREF="http://ln.hixie.ch/">http://ln.hixie.ch/</A>       U+263A                /,   _.. \   _\  ;`._ ,.
</I>&gt;<i> Things that are impossible just take longer.   `._.-(,_..'--(,_..'`-.;.'
</I></PRE>










<!--endarticle-->
<!--htdig_noindex-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="031213.html">[whatwg]  PeerConnection feedback
</A></li>
	<LI>Next message: <A HREF="031232.html">[whatwg] PeerConnection feedback
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#31217">[ date ]</a>
              <a href="thread.html#31217">[ thread ]</a>
              <a href="subject.html#31217">[ subject ]</a>
              <a href="author.html#31217">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">More information about the whatwg
mailing list</a><br>
<!--/htdig_noindex-->
</body></html>
