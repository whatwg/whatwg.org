<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [whatwg] Stream API Feedback
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20Stream%20API%20Feedback&In-Reply-To=%3CAANLkTi%3DZtM7ORYx%2Bqco9zTayYNm0z3rfNfzhOFDvMOJp%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="073200.html">
   <LINK REL="Next"  HREF="073193.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[whatwg] Stream API Feedback</H1>
<!--htdig_noindex-->
    <B>Robert O'Callahan</B> 
    <A HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20Stream%20API%20Feedback&In-Reply-To=%3CAANLkTi%3DZtM7ORYx%2Bqco9zTayYNm0z3rfNfzhOFDvMOJp%40mail.gmail.com%3E"
       TITLE="[whatwg] Stream API Feedback">robert at ocallahan.org
       </A><BR>
    <I>Wed Mar 16 20:22:21 PDT 2011</I>
    <P><UL>
        <LI>Previous message: <A HREF="073200.html">[whatwg] Stream API Feedback
</A></li>
        <LI>Next message: <A HREF="073193.html">[whatwg] Stream API Feedback
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#73192">[ date ]</a>
              <a href="thread.html#73192">[ thread ]</a>
              <a href="subject.html#73192">[ subject ]</a>
              <a href="author.html#73192">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--/htdig_noindex-->
<!--beginarticle-->
<PRE>On Thu, Mar 17, 2011 at 4:36 AM, Lachlan Hunt &lt;<A HREF="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">lachlan.hunt at lachy.id.au</A>&gt;wrote:

&gt;<i> I'm not entirely sure I understand your proposal, but are you suggesting
</I>&gt;<i> that the input streams from the camera/microphone would first go to &lt;video&gt;
</I>&gt;<i> and &lt;audio&gt; elements, allowing the existing HTMLMediaElement API on those
</I>&gt;<i> elements to be used to control those streams, the output of which can then
</I>&gt;<i> be encoded and recorded to a file or streamed remotely?
</I>&gt;<i>
</I>
Yes.

In fact, of all the properties that are on HTMLMediaElement, the only ones
&gt;<i> that seem to have any real use for streaming media are volume, muted, paused
</I>&gt;<i> and ended.  So I'm not convinced that it's a good idea to try and reuse
</I>&gt;<i> existing APIs simple for the sake of reusing them, when they aren't really a
</I>&gt;<i> good fit.
</I>

As Olli said, &lt;video&gt; and &lt;audio&gt; are designed to support streaming media;
streaming over a low-latency network is very much like streaming from a
local device.

In Gecko, we allow seeking within cached segements of streamed video, and we
could easily allow that for local devices too --- user-controlled &quot;instant
replay&quot;.

So for an HTML video element, the following attributes could all make sense
for streaming from local devices, IMHO:
-- videoWidth/videoHeight
-- width/height (reflected to CSS)
-- poster (to show a placeholder before camera input becomes available)
-- controls (in-page controls for mute, start/stop)
-- src
-- readyState
-- currentTime (read and write)
-- paused
-- ended (the user turned off the camera)
-- duration
-- volume
-- seeking
-- seekable
-- buffered
-- played

But that's not particularly useful for the audio element. It's rare that the
&gt;<i> user would want their microphone input to be echoed back to them via an
</I>&gt;<i> audio element. In most cases, when a microphone stream is input into an
</I>&gt;<i> audio element, the audio element itself would need to be muted to prevent
</I>&gt;<i> unwanted and annoying echo or, worse, feedback loops.
</I>

Yes, direct audio output would have to be muted. This could be done
automatically when input is coming directly from a local device. (Assuming
that using your Web browser as a megaphone is not a valid use-case :-).)

That would only be useful if the audio data were being analysed and output,
&gt;<i> for example, to an audio spectrum visualisation (like with Mozilla's
</I>&gt;<i> experimental audio data API).
</I>

Not just analysis, but also processing. For example, XBox Live lets you
distort your audio input in voice chat.

Rob
-- 
&quot;Now the Bereans were of more noble character than the Thessalonians, for
they received the message with great eagerness and examined the Scriptures
every day to see if what Paul said was true.&quot; [Acts 17:11]

</PRE>

<!--endarticle-->
<!--htdig_noindex-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="073200.html">[whatwg] Stream API Feedback
</A></li>
	<LI>Next message: <A HREF="073193.html">[whatwg] Stream API Feedback
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#73192">[ date ]</a>
              <a href="thread.html#73192">[ thread ]</a>
              <a href="subject.html#73192">[ subject ]</a>
              <a href="author.html#73192">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">More information about the whatwg
mailing list</a><br>
<!--/htdig_noindex-->
</body></html>
