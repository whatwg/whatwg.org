<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [whatwg] Audio canvas?
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20Audio%20canvas%3F&In-Reply-To=%3C487DF506.1070505%40svox.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="057602.html">
   <LINK REL="Next"  HREF="057604.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[whatwg] Audio canvas?</H1>
<!--htdig_noindex-->
    <B>Dr. Markus Walther</B> 
    <A HREF="mailto:whatwg%40lists.whatwg.org?Subject=Re%3A%20%5Bwhatwg%5D%20Audio%20canvas%3F&In-Reply-To=%3C487DF506.1070505%40svox.com%3E"
       TITLE="[whatwg] Audio canvas?">walther at svox.com
       </A><BR>
    <I>Wed Jul 16 06:17:58 PDT 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="057602.html">[whatwg] Audio canvas?
</A></li>
        <LI>Next message: <A HREF="057604.html">[whatwg] Audio canvas?
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#57603">[ date ]</a>
              <a href="thread.html#57603">[ thread ]</a>
              <a href="subject.html#57603">[ subject ]</a>
              <a href="author.html#57603">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--/htdig_noindex-->
<!--beginarticle-->
<PRE>
 &gt;&gt; My understanding of HTMLMediaElement is that the currentTime, volume
 &gt;&gt; and playbackRate properties can be modified live.
 &gt;&gt;
 &gt;&gt; So in a way Audio is already like Canvas : the developer modify things
 &gt;&gt; on the go. There is no automated animations/transitions like in SVG
 &gt;&gt; for instance.
 &gt;&gt;
 &gt;&gt; Doing a cross fade in Audio is done exactly the same way as in Canvas.

That's not what I described, however. Canvas allows access to the most 
primitive element with which an image is composed, the pixel. Audio does 
not allow access to the sample, which is the equivalent of pixel in the 
sound domain. That's a severe limitation. Using tricks with data URIs 
and a known simple audio format such as PCM WAVE is no real substitute, 
because JavaScript strings are immutable.

It is unclear to me why content is still often seen as static by default 
- if desktop apps are moved to the browser, images and sound will 
increasingly be generated and modified on-the-fly, client-side.

 &gt; And if you're thinking special effects ( e.g.: delay, chorus, flanger,
 &gt; pass band, ... ) remember that with Canvas, advanced effects require
 &gt; trickery and to composite multiple Canvas elements.

I have use cases in mind like an in-browser audio editor for music or 
speech applications (think 'Cooledit/Audacity in a browser'), where 
doing everything server-side would be prohibitive due to the amount of 
network traffic.

--Markus

</PRE>

<!--endarticle-->
<!--htdig_noindex-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="057602.html">[whatwg] Audio canvas?
</A></li>
	<LI>Next message: <A HREF="057604.html">[whatwg] Audio canvas?
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#57603">[ date ]</a>
              <a href="thread.html#57603">[ thread ]</a>
              <a href="subject.html#57603">[ subject ]</a>
              <a href="author.html#57603">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.whatwg.org/listinfo.cgi/whatwg-whatwg.org">More information about the whatwg
mailing list</a><br>
<!--/htdig_noindex-->
</body></html>
